import streamlit as st
import time
from pathlib import Path
import uuid
import json
from flashrag.config import Config
from flashrag.utils import get_retriever, get_generator
from flashrag.prompt import PromptTemplate
import base64
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "3,6"
os.environ["STREAMLIT_WATCHER_TYPE"] = "none" # æ§åˆ¶ Streamlit æ–‡ä»¶çƒ­é‡è½½æœºåˆ¶ çš„ç¯å¢ƒå˜é‡ï¼Œä¸»è¦ä½œç”¨æ˜¯å†³å®š Streamlit ç›‘å¬å“ªäº›æºæ–‡ä»¶çš„å˜åŠ¨ï¼Œä»¥è‡ªåŠ¨é‡æ–°è¿è¡Œ appã€‚
# é…ç½®RAGç›¸å…³å‚æ•°
config_dict = {
    "save_note": "demo",
    'data_dir': 'dataset/',
    'index_path': 'indexes/e5_Flat.index',
    'corpus_path': 'indexes/general_knowledge.jsonl',
    'model2path': {'e5': '/home/u2021201791/workspace/Model/intfloat/e5-base-v2'},
    'openai_setting':{'api_key':'sk-40b478c515bf4de38b60511ee63f56b5', 'base_url':'https://api.deepseek.com/v1'},
    'generator_model': 'deepseek-chat',
    'framework': 'openai',
    'retrieval_method': 'e5',
    'metrics': ['em','f1','acc'],
    'retrieval_topk': 1,
    'save_intermediate_data': True
}

# ç¼“å­˜åŠ è½½æ£€ç´¢å™¨ï¼ˆé¿å…é‡å¤åŠ è½½ï¼Œæå‡æ•ˆç‡ï¼‰
@st.cache_resource
def load_retriever(_config):
    return get_retriever(_config)

# ç¼“å­˜åŠ è½½ç”Ÿæˆå™¨
@st.cache_resource
def load_generator(_config):
    return get_generator(_config)

# é¢„åŠ è½½é…ç½®å’Œæ¨¡å‹
@st.cache_resource
def initialize_models():
    """åœ¨åº”ç”¨å¯åŠ¨æ—¶é¢„åŠ è½½æ‰€æœ‰æ¨¡å‹å’Œé…ç½®"""
    config = Config("../methods/my_config.yaml", config_dict=config_dict)
    retriever = load_retriever(config)
    generator = load_generator(config)
    return config, retriever, generator

# é¦–æ¬¡è®¿é—®æ—¶åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å˜é‡
if 'conversation_history' not in st.session_state:
    st.session_state.conversation_history = []  # ä¿å­˜å¯¹è¯è®°å½•
    
if 'memory_chat_history' not in st.session_state:
    st.session_state.memory_chat_history = []  # ç”¨äºLLMå†…éƒ¨è®°å¿†çš„å¯¹è¯å†å²
    
if 'conversation_id' not in st.session_state:
    st.session_state.conversation_id = str(uuid.uuid4())    # å½“å‰ä¼šè¯å”¯ä¸€æ ‡è¯†ç¬¦
    
if 'user_avatar' not in st.session_state:
    st.session_state.user_avatar = "ğŸ‘¤"  # ç”¨æˆ·å¤´åƒé»˜è®¤å€¼
    
if 'assistant_avatar' not in st.session_state:
    st.session_state.assistant_avatar = "ğŸ¤–"  # åŠ©æ‰‹æœºå™¨äººå¤´åƒé»˜è®¤å€¼

if 'query_input' not in st.session_state:
    st.session_state.query_input = ""   # åˆå§‹åŒ–ç”¨æˆ·è¾“å…¥å†…å®¹ä¸ºç©º

# åˆå§‹åŒ–æ¨¡å‹åŠ è½½çŠ¶æ€
if 'models_loaded' not in st.session_state:
    st.session_state.models_loaded = False
    
if 'models_loading' not in st.session_state:
    st.session_state.models_loading = False

    
# æäº¤é—®é¢˜åæ¸…ç©ºè¾“å…¥æ¡†
def clear_input():
    st.session_state.query_input = ""

# ä¿å­˜å½“å‰å¯¹è¯è®°å½•åˆ°æœ¬åœ° JSON æ–‡ä»¶
def save_conversation():
    conversations_dir = Path("conversations")
    conversations_dir.mkdir(exist_ok=True)  # å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºå¯¹è¯ç›®å½•
    
    conversation_file = conversations_dir / f"{st.session_state.conversation_id}.json"
    
    with open(conversation_file, 'w') as f:
        json.dump({
            "id": st.session_state.conversation_id,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "messages": st.session_state.conversation_history,
            "memory_chat_history": st.session_state.memory_chat_history  # ä¿å­˜å†…éƒ¨è®°å¿†å†å²
        }, f)

# è¯»å–å†å²å¯¹è¯è®°å½•
def load_conversation(conversation_id):
    conversation_file = Path("conversations") / f"{conversation_id}.json"
    if conversation_file.exists():
        with open(conversation_file, 'r') as f:
            data = json.load(f)
            st.session_state.conversation_history = data["messages"]
            # åŠ è½½å†…éƒ¨è®°å¿†å†å²ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨
            st.session_state.memory_chat_history = data.get("memory_chat_history", [])
            st.session_state.conversation_id = conversation_id

# å¯åŠ¨æ–°çš„å¯¹è¯å¹¶æ¸…ç©ºå†å²è®°å½•
def start_new_conversation():
    st.session_state.conversation_history = []
    st.session_state.memory_chat_history = []  # åŒæ—¶æ¸…ç©ºå†…éƒ¨è®°å¿†å†å²
    st.session_state.conversation_id = str(uuid.uuid4())

# å°†å¯¹è¯å†å²æ ¼å¼åŒ–ä¸ºé€‚åˆLLMå†…å­˜çš„æ ¼å¼
def format_chat_history_for_llm(history):
    formatted_messages = []
    for msg in history:
        if msg["role"] == "user":
            formatted_messages.append({"role": "user", "content": msg["content"]})
        elif msg["role"] == "assistant":
            formatted_messages.append({"role": "assistant", "content": msg["content"]})
    return formatted_messages

def main():
    # Streamlité¡µé¢é…ç½®
    custom_theme = {
        "primaryColor": "#0099cc",
        "backgroundColor": "#f0f0f0",
        "secondaryBackgroundColor": "#d3d3d3",
        "textColor": "#121212",
        "font": "sans serif"
    }
    
    # Page configuration
    st.set_page_config(
        page_title="GSAIå­¦ç”Ÿæˆé•¿åŠ©æ‰‹", 
        page_icon="ğŸ¤–",
        layout="wide"
    )

    # è‡ªå®šä¹‰å‰ç«¯ CSS æ ·å¼ï¼ŒåŒ…æ‹¬å®ç°èŠå¤©æ°”æ³¡ã€åº•éƒ¨è¾“å…¥æ¡†ç­‰
    st.markdown("""
    <style>
        .main .block-container {
            padding-top: 2rem;
            padding-bottom: 6rem;
        }
        .stTextArea textarea {
            border-radius: 20px;
        }
        .user-bubble {
            background-color: #CCE6Fe;
            padding: 10px 15px;
            border-radius: 18px;
            margin: 5px 0;
            display: inline-block;
            max-width: 80%;
            float: right;
            clear: both;
            position: relative;
        }
        .assistant-bubble {
            background-color: #E6F2F9;
            padding: 10px 15px;
            border-radius: 18px;
            margin: 5px 0;
            display: inline-block;
            max-width: 80%;
            float: left;
            clear: both;
            position: relative;
            box-shadow: 0 1px 2px rgba(0,0,0,0.1);
        }
        .chat-container {
            overflow-y: auto;
            height: calc(100vh - 250px);
            display: flex;
            flex-direction: column;
        }
        .reference-box {
            background-color: #f8f9fa;
            border-left: 3px solid #66b3d9;
            padding: 10px;
            margin: 10px 0;
            font-size: 0.9em;
        }
        .chat-input {
            position: fixed;
            bottom: 0;
            width: 65%;
            background-color: white;
            padding: 1rem 0;
            z-index: 1000;
            # box-shadow: 0 -2px 10px rgba(0,0,0,0.1);
        }
        .new-chat-btn {
            margin-bottom: 20px;
        }
        .sidebar .sidebar-content {
            background-color: #f8f9fa;
        }
        .memory-info {
            font-size: 0.8em;
            color: #666;
            margin-top: 5px;
            font-style: italic;
        }
        .avatar {
            width: 36px;
            height: 36px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 20px;
        }
        /* è¾“å…¥æ¡†èšç„¦æ—¶è¾¹æ¡†å˜è“ */
        .stTextArea textarea:focus {
            outline: none !important;
            border: 2px solid #0099cc !important;
            box-shadow: 0 0 5px rgba(0, 153, 204, 0.5);
        }

        /* æŒ‰é’®èšç„¦æ—¶å­—ä½“é¢œè‰²å˜è“ */
        button {
            /* é»˜è®¤çŠ¶æ€ï¼šæ–‡å­—å·¦å¯¹é½ + æµ…ç°è‰²å­—ä½“ */
            text-align: left !important;
            color: #313131 !important;
            background-color: white;
            border: 1px solid #ccc;
            padding: 10px 15px;
            font-size: 14px;
            cursor: pointer;
        }

        /* æ‚¬åœçŠ¶æ€ */
        button:hover {
            color: #66b3d9 !important;
            border: 1px solid #0099cc !important;
        }

        /* èšç„¦çŠ¶æ€ */
        button:focus {
            color: #66b3d9 !important;
            background-color: #f8f9fa !important;
            border: none !important;
            outline: none;
            box-shadow: 0 0 5px 2px rgba(0, 153, 204, 0.5) !important;
        }

        .loading-indicator {
            background-color: #e3f2fd;
            border: 1px solid #66b3d9;
            border-radius: 10px;
            padding: 15px;
            margin: 20px 0;
            text-align: center;
            color: #1976d2;
        }
                
    </style>
    """, unsafe_allow_html=True)

    # åœ¨é¡µé¢å¼€å§‹æ—¶å°±å¯åŠ¨æ¨¡å‹åŠ è½½
    col1, main_col, col3 = st.columns([2, 4, 2])
    
    with main_col:
        # æ¬¢è¿é¡µé¢
        if not st.session_state.models_loaded and not st.session_state.models_loading:
            st.session_state.models_loading = True
            
            # æ˜¾ç¤ºåŠ è½½æç¤º
            loading_placeholder = st.empty()
            with loading_placeholder:
                st.markdown("""
                <div class="loading-indicator">
                    <h3>ğŸš€ æ­£åœ¨åˆå§‹åŒ–AIåŠ©æ‰‹...</h3>
                    <p>é¦–æ¬¡åŠ è½½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·ç¨å€™ç‰‡åˆ»</p>
                </div>
                """, unsafe_allow_html=True)
            
            # é¢„åŠ è½½æ¨¡å‹
            try:
                config, retriever, generator = initialize_models()
                st.session_state.config = config
                st.session_state.retriever = retriever
                st.session_state.generator = generator
                st.session_state.models_loaded = True
                st.session_state.models_loading = False
                
                # æ¸…é™¤åŠ è½½æç¤º
                loading_placeholder.empty()
                
                # æ˜¾ç¤ºåŠ è½½å®Œæˆæç¤ºï¼ˆçŸ­æš‚æ˜¾ç¤ºåæ¶ˆå¤±ï¼‰
                success_placeholder = st.empty()
                with success_placeholder:
                    st.success("âœ… AIåŠ©æ‰‹å·²å‡†å¤‡å°±ç»ªï¼")
                
                # 2ç§’åæ¸…é™¤æˆåŠŸæç¤ºå¹¶åˆ·æ–°é¡µé¢
                time.sleep(2)
                success_placeholder.empty()
                st.rerun()
                
            except Exception as e:
                loading_placeholder.empty()
                st.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
                st.session_state.models_loading = False
                return
    
    # å¦‚æœæ­£åœ¨åŠ è½½ï¼Œæ˜¾ç¤ºåŠ è½½ç•Œé¢
    if st.session_state.models_loading:
        st.markdown("""
        <div class="loading-indicator">
            <h3>ğŸš€ æ­£åœ¨åˆå§‹åŒ–AIåŠ©æ‰‹...</h3>
            <p>é¦–æ¬¡åŠ è½½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·ç¨å€™ç‰‡åˆ»</p>
        </div>
        """, unsafe_allow_html=True)
        return

    # å¯¹è¯å‚æ•°
    temperature = 0.5
    topk = 5
    max_new_tokens = 256
    memory_window = 5
    st.session_state.user_avatar = "ğŸ‘¤"
    st.session_state.assistant_avatar = "ğŸ¤–"
    # å·¦ä¾§è¾¹æ è®¾ç½®ä¸å†å²å¯¹è¯
    with st.sidebar:
        st.title("_GSAI_ :blue[å­¦ç”Ÿæˆé•¿åŠ©æ‰‹]")
        
        # # æ˜¾ç¤ºæ¨¡å‹çŠ¶æ€
        # if st.session_state.models_loaded:
        #     st.success("ğŸŸ¢ AIåŠ©æ‰‹å·²å°±ç»ª")
        # else:
        #     st.warning("ğŸŸ¡ AIåŠ©æ‰‹åŠ è½½ä¸­...")
        
        # å¦‚æœæ–°å»ºå¯¹è¯ï¼Œåˆ™åˆ·æ–°é¡µé¢æ–°å»ºå¯¹è¯
        if st.button("æ–°å»ºå¯¹è¯", key="new_chat", use_container_width=True):
            start_new_conversation()
            st.rerun()
        
        st.divider()
        
        # å¯¹è¯å†å²
        st.subheader("å¯¹è¯å†å²")
        
        # å·¦è¾¹æ çš„å†å²å¯¹è¯
        conversations_dir = Path("conversations")
        conversations_dir.mkdir(exist_ok=True)
        conversation_files = list(conversations_dir.glob("*.json"))

        conversations = []

        # åŠ è½½æ‰€æœ‰å¯¹è¯å¹¶æå–æ—¶é—´æˆ³ä¿¡æ¯
        for conv_file in conversation_files:
            try:
                with open(conv_file, 'r') as f:
                    data = json.load(f)
                    timestamp = data.get("timestamp", "")
                    conversations.append((timestamp, data))
            except Exception as e:
                st.error(f"Error loading conversation: {e}")

        # æŒ‰ timestamp é€†åºæ’åºï¼ˆè¶Šæ–°è¶Šé å‰ï¼‰
        conversations.sort(key=lambda x: x[0], reverse=True)

        if conversations:
            for timestamp, data in conversations:
                # å†å²å¯¹è¯çš„ title
                title = data.get("timestamp", "Untitled")
                for msg in data.get("messages", []):
                    if msg["role"] == "user":
                        title = msg["content"][:20] + "..." if len(msg["content"]) > 20 else msg["content"]
                        break

                if st.button(title, key=f"conv_{data['id']}", use_container_width=True):
                    load_conversation(data["id"])
                    st.rerun()
        else:
            st.write("æ²¡æœ‰å…ˆå‰å¯¹è¯å†å²")
    
    # ä½¿ç”¨ä¸‰åˆ—å¸ƒå±€ï¼Œå°†ä¸­é—´åˆ—ç”¨äºå¯¹è¯
    col1, main_col, col3 = st.columns([2, 4, 2])
    
    with main_col:
        # æ¬¢è¿é¡µé¢
        if not st.session_state.conversation_history:
            # è¯»å–å¹¶ç¼–ç å›¾ç‰‡
            image_path = "/home/u2021201791/workspace/FlashRAG/examples/quick_start/ai_logo.jpg"
            try:
                with open(image_path, "rb") as f:
                    data = f.read()
                    encoded = base64.b64encode(data).decode()

                st.markdown(f"""
                <div style="text-align: center; display: flex; align-items: center; margin-top: 200px; width: fit-content; margin-left: auto; margin-right: auto;">
                    <img src="data:image/jpeg;base64,{encoded}"
                        style="height: 120px; margin-right: 20px;" />
                    <div>
                        <h1 style="color: #66b3d9; margin: 0;">æ¬¢è¿ğŸ‘æˆ‘æ˜¯é«˜ç“´AIå­¦ç”Ÿæˆé•¿åŠ©æ‰‹</h1>
                        <p style="margin-top: 0.3em;">æˆ‘å¯ä»¥å¸®ä½ è§£å†³å­¦ä¹ ç”Ÿæ´»ä¸Šé‡åˆ°çš„é—®é¢˜ï¼Œä¸æ¸…æ¥šçš„åœ°æ–¹å¿«æ¥é—®é—®æˆ‘å§ï½</p>
                    </div>
                </div>
                """, unsafe_allow_html=True)
            except FileNotFoundError:
                st.markdown("""
                <div style="text-align: center; margin-top: 200px;">
                    <h1 style="color: #66b3d9;">æ¬¢è¿ğŸ‘æˆ‘æ˜¯é«˜ç“´AIå­¦ç”Ÿæˆé•¿åŠ©æ‰‹</h1>
                    <p>æˆ‘å¯ä»¥å¸®ä½ è§£å†³å­¦ä¹ ç”Ÿæ´»ä¸Šé‡åˆ°çš„é—®é¢˜ï¼Œä¸æ¸…æ¥šçš„åœ°æ–¹å¿«æ¥é—®é—®æˆ‘å§ï½</p>
                </div>
                """, unsafe_allow_html=True)
        
        # å±•ç¤ºå¯¹è¯å†…å®¹ï¼Œä¹Ÿå°±æ˜¯èŠå¤©æ°”æ³¡
        chat_container = st.container()
        with chat_container:
            for message in st.session_state.conversation_history:
                role = message["role"]
                content = message["content"]
                
                if role == "user":
                    avatar = "/home/u2021201791/workspace/FlashRAG/examples/quick_start/user_avatar.jpg"
                    with open(avatar, "rb") as f:
                        data = f.read()
                        encoded_user = base64.b64encode(data).decode()
                    st.markdown(f'''
                    <div style="display: flex; justify-content: flex-end; align-items: flex-start; margin: 10px 0;">
                        <div class="user-bubble">{content}</div>
                        <img src="data:image/jpeg;base64,{encoded_user}" style="height: 24px; margin-left: 10px;" />
                    </div>
                    <div style="clear: both;"></div>
                    ''', unsafe_allow_html=True)
                elif role == "assistant":
                    avatar = "/home/u2021201791/workspace/FlashRAG/examples/quick_start/assistant_avatar.jpg"
                    with open(avatar, "rb") as f:
                        data = f.read()
                        encoded_user = base64.b64encode(data).decode()
                    st.markdown(f'''
                    <div style="display: flex; justify-content: flex-start; align-items: flex-start; margin: 10px 0;">
                        <img src="data:image/jpeg;base64,{encoded_user}" style="height: 24px; margin-right: 10px;" />
                        <div class="assistant-bubble">{content}</div>
                    </div>
                    <div style="clear: both;"></div>
                    ''', unsafe_allow_html=True)
                

                    # æ˜¾ç¤ºå¼•ç”¨æ–‡æ¡£
                    if "references" in message:
                        with st.expander("æŸ¥çœ‹ç­”æ¡ˆæ¥æº", expanded=False):
                            for i, ref in enumerate(message["references"]):
                                doc_title = ref.get("title", "No Title")
                                doc_text = "\n".join(ref["contents"].split("\n")[1:]) if "contents" in ref else "No content available"
                                st.markdown(f"""
                                <div class="reference-box">
                                    <strong>[{i+1}]: {doc_title}</strong>
                                    <p>{doc_text}</p>
                                </div>
                                """, unsafe_allow_html=True)
    
        # åº•éƒ¨æ‚¬æµ®çš„è¾“å…¥æ¡†åŒºåŸŸ
        # åªæœ‰åœ¨æ¨¡å‹åŠ è½½å®Œæˆåæ‰æ˜¾ç¤ºè¾“å…¥æ¡†
        if st.session_state.models_loaded:
            query = st.chat_input("éšä¾¿é—®ç‚¹ä»€ä¹ˆ")
            if query:
                # Get the stored query
                user_query = query
                
                # æ·»åŠ æ–°çš„ç”¨æˆ·æ¶ˆæ¯åˆ°å¯¹è¯å†å²
                st.session_state.conversation_history.append({
                    "role": "user",
                    "content": user_query
                })
                
                # åŒæ—¶æ›´æ–°å†…å­˜å¯¹è¯å†å²
                st.session_state.memory_chat_history.append({
                    "role": "user",
                    "content": user_query
                })
                
                # ä½¿ç”¨é¢„åŠ è½½çš„æ¨¡å‹å®ä¾‹
                config = st.session_state.config
                generator = st.session_state.generator
                retriever = st.session_state.retriever
                
                # è·å–è®¾ç½®ä¸­çš„memory_windowå€¼
                memory_window = st.session_state.get('memory_window', 3)
                
                # åªä¿ç•™æœ€è¿‘çš„å‡ è½®å¯¹è¯ä½œä¸ºä¸Šä¸‹æ–‡
                recent_memory = st.session_state.memory_chat_history[-2*memory_window:] if len(st.session_state.memory_chat_history) > 2*memory_window else st.session_state.memory_chat_history
                
                # æ„å»ºå¸¦æœ‰å¯¹è¯å†å²çš„system prompt
                chat_history_str = ""
                if recent_memory:
                    for msg in recent_memory:
                        role = "Human" if msg["role"] == "user" else "Assistant"
                        chat_history_str += f"{role}: {msg['content']}\n\n"
                
                system_prompt_rag = (
                    "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚"
                    "è¯·å¯¹ç”¨æˆ·çš„è¾“å‡ºåšå‡ºé«˜è´¨é‡çš„å“åº”ï¼Œç”Ÿæˆç±»ä¼¼äºäººç±»çš„å†…å®¹ï¼Œå¹¶å°½é‡éµå¾ªè¾“å…¥ä¸­çš„æŒ‡ä»¤ã€‚"
                    "\n\nä»¥ä¸‹æ˜¯ä¹‹å‰çš„å¯¹è¯å†å²ï¼Œè¯·åŸºäºè¿™äº›å†å²æä¾›è¿è´¯çš„å›å¤ï¼š\n\n{chat_history}"
                    "\n\nä¸‹é¢æ˜¯ä¸€äº›å¯ä¾›å‚è€ƒçš„æ–‡æ¡£ï¼Œä½ å¯ä»¥ä½¿ç”¨å®ƒä»¬æ¥å›ç­”é—®é¢˜ï¼š\n\n{reference}"
                )
                
                base_user_prompt = "{question}"
                prompt_template_rag = PromptTemplate(config, system_prompt=system_prompt_rag, user_prompt=base_user_prompt)
                
                # with st.spinner("æ£€ç´¢å¹¶æ€è€ƒä¸­..."):
                with st.status("æ­£åœ¨åŠªåŠ›æ€è€ƒä¸­...", expanded=False) as status:
                    with st.spinner("æ­£åœ¨æ£€ç´¢ç›¸åº”æ–‡æ¡£...", show_time=True):
                        retrieved_docs = retriever.search(user_query, num=topk)

                    st.write("å·²æ£€ç´¢ç›¸å…³æ–‡æ¡£")
                    with st.spinner("æ­£åœ¨å›é¡¾å†å²ä¿¡æ¯...", show_time=True):
                        # Generate response with RAG and conversation history
                        input_prompt_with_rag = prompt_template_rag.get_string(
                            question=user_query, 
                            retrieval_result=retrieved_docs,
                            chat_history=chat_history_str  # æ·»åŠ å¯¹è¯å†å²åˆ°prompt
                        )
                    st.write("å·²å›é¡¾å†å²ä¿¡æ¯")
                    with st.spinner("æ­£åœ¨ç”Ÿæˆæœ€ç»ˆå›å¤...", show_time=True):
                        response_with_rag = generator.generate(
                            input_prompt_with_rag, 
                            temperature=temperature, 
                            max_new_tokens=max_new_tokens
                        )[0]
                    # æŠŠå›å¤æ·»åŠ åˆ°UIæ˜¾ç¤ºçš„å¯¹è¯å†å²
                    st.write("å·²ç”Ÿæˆæœ€ç»ˆå›å¤")
                    st.session_state.conversation_history.append({
                        "role": "assistant",
                        "content": response_with_rag,
                        "references": retrieved_docs
                    })
                    
                    # åŒæ—¶æ·»åŠ åˆ°å†…éƒ¨è®°å¿†
                    st.session_state.memory_chat_history.append({
                        "role": "assistant",
                        "content": response_with_rag
                    })
                    
                    # ä¿å­˜å¯¹è¯
                    save_conversation()
                    status.update(
                        label="æˆåŠŸ!", state="complete", expanded=False
                    )
                    # é‡æ–°å¼€å§‹
                    st.rerun()

if __name__ == '__main__':
    main()